{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, num_input, num_hidden, num_output):\n",
    "        self.ni = num_input\n",
    "        self.nh = num_hidden\n",
    "        self.no = num_output\n",
    "    def set_weight(self, weight):\n",
    "        pass\n",
    "    def get_weights(self):\n",
    "        pass\n",
    "    def eval(self, X_values):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num_row, x_num_col =[2, 10000]\n",
    "x_raw = np.random.rand(x_num_row, x_num_col) * 100\n",
    "y_raw = np.concatenate(([(x_raw[0,:] + x_raw[1,:])],[(x_raw[0,:] - x_raw[1,:])], np.abs([(x_raw[0,:] - x_raw[1,:])])))\n",
    "y_num_row, y_num_col = y_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_num_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94.15499441, 147.04522402, 132.00734152, ..., 178.52667839,\n",
       "        172.48599836, 122.59327854],\n",
       "       [ 23.4711658 ,  32.49752156,  46.29880437, ...,   8.18167411,\n",
       "        -25.85461472, -51.7195167 ],\n",
       "       [ 23.4711658 ,  32.49752156,  46.29880437, ...,   8.18167411,\n",
       "         25.85461472,  51.7195167 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58.81308011, 89.77137279, 89.15307295, ..., 93.35417625,\n",
       "        73.31569182, 35.43688092],\n",
       "       [35.3419143 , 57.27385123, 42.85426857, ..., 85.17250214,\n",
       "        99.17030654, 87.15639762]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "num_train_datum = int(train_ratio * x_num_col)\n",
    "x_raw_test = x_raw[:,0:num_train_datum]\n",
    "x_raw_test = x_raw[:,num_train_datum:]\n",
    "x_raw_train = y_raw[:,0:num_train_datum]\n",
    "y_raw_train = y_raw[:,num_train_datum:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2180732613030288e-17, 1.522591576628786e-18]\n",
      "[-1.2180732613030288e-17, 1.522591576628786e-18]\n",
      "[-9.769962616701378e-17, -1.4210854715202004e-17, 5.684341886080802e-17]\n",
      "[0.9999999999999999, 0.9999999999999999, 1.0]\n"
     ]
    }
   ],
   "source": [
    "class scaler:\n",
    "    def __init__(self,mean,std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "def get_scaler(row):\n",
    "    mean = np.mean(row)\n",
    "    std = np.std(row)\n",
    "    return scaler(mean,std)\n",
    "\n",
    "def standardize(data, scaler):\n",
    "    return (data - scaler.mean) / scaler.std\n",
    "\n",
    "def unstandardize(data, scaler):\n",
    "    return (data * scalers.std) + scalers.mean\n",
    "\n",
    "\n",
    "\n",
    "x_scalers = [get_scaler(x_raw_train[row,:]) for row in range(x_num_row)]\n",
    "x_train = np.array([standardize(x_raw_train[row,:], x_scalers[row]) for row in range(x_num_row)])\n",
    "\n",
    "y_scalers = [get_scaler(y_raw_train[row,:]) for row in range(y_num_row)]\n",
    "\n",
    "y_train = np.array([standardize(y_raw_train[row,:], y_scalers[row]) for row in range(y_num_row)])\n",
    "\n",
    "x_test = np.array([standardize(x_raw_test[row,:], x_scalers[row]) for row in range(x_num_row)])\n",
    "y_test = np.array([standardize(y_raw_test[row,:], y_scalers[row]) for row in range(y_num_row)])\n",
    "\n",
    "print([x_train[row,:].mean() for row in range(x_num_row)])\n",
    "print([x_train[row,:].mean() for row in range(x_num_row)])\n",
    "\n",
    "print([y_train[row,:].mean() for row in range(y_num_row)])\n",
    "print([y_train[row,:].std() for row in range(y_num_row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9897704]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "class NeuralNet(object): \n",
    "\tdef __init__(self): \n",
    "\t\t# Generate random numbers \n",
    "\t\trandom.seed(1) \n",
    "\n",
    "\t\t# Assign random weights to a 3 x 1 matrix, \n",
    "\t\tself.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
    "\n",
    "\t# The Sigmoid function \n",
    "\tdef __sigmoid(self, x): \n",
    "\t\treturn 1 / (1 + exp(-x)) \n",
    "\n",
    "\t# The derivative of the Sigmoid function. \n",
    "\t# This is the gradient of the Sigmoid curve. \n",
    "\tdef __sigmoid_derivative(self, x): \n",
    "\t\treturn x * (1 - x) \n",
    "\n",
    "\t# Train the neural network and adjust the weights each time. \n",
    "\tdef train(self, inputs, outputs, training_iterations): \n",
    "\t\tfor iteration in range(training_iterations): \n",
    "\n",
    "\t\t\t# Pass the training set through the network. \n",
    "\t\t\toutput = self.learn(inputs) \n",
    "\n",
    "\t\t\t# Calculate the error \n",
    "\t\t\terror = outputs - output \n",
    "\n",
    "\t\t\t# Adjust the weights by a factor \n",
    "\t\t\tfactor = dot(inputs.T, error * self.__sigmoid_derivative(output)) \n",
    "\t\t\tself.synaptic_weights += factor \n",
    "\n",
    "\t# The neural network thinks. \n",
    "\tdef learn(self, inputs): \n",
    "\t\treturn self.__sigmoid(dot(inputs, self.synaptic_weights)) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "\n",
    "\t#Initialize \n",
    "\tneural_network = NeuralNet() \n",
    "\n",
    "\t# The training set. \n",
    "\tinputs = array([[0, 1, 1], [1, 0, 0], [1, 0, 1]]) \n",
    "\toutputs = array([[1, 0, 1]]).T \n",
    "\n",
    "\t# Train the neural network \n",
    "\tneural_network.train(inputs, outputs, 10000) \n",
    "\n",
    "\t# Test the neural network with a test example. \n",
    "\tprint(neural_network.learn(array([1, 0, 1]))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
